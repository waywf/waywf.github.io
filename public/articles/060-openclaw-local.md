---
title: OpenClaw + Ollama + é£ä¹¦æœºå™¨äººï¼šæ‰“é€ ä¼ä¸šçº§AIåŠ©æ‰‹çš„å®Œæ•´å®æˆ˜
category: AI
excerpt: æ·±å…¥æ¢ç´¢OpenClawä¸Ollamaçš„å¼ºå¼ºè”åˆï¼Œä»æœ¬åœ°æ¨¡å‹éƒ¨ç½²åˆ°é£ä¹¦æœºå™¨äººé›†æˆï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ æ­å»ºä¼ä¸šçº§AIåŠ©æ‰‹ï¼Œå®ç°æ•°æ®éšç§ä¸æ™ºèƒ½æœåŠ¡çš„å®Œç¾å¹³è¡¡ã€‚
tags: OpenClaw, Ollama, é£ä¹¦æœºå™¨äºº, æœ¬åœ°éƒ¨ç½², ä¼ä¸šAI, LLM, å›½äº§æ¨¡å‹
date: 2026-01-29
readTime: 35
---

## ä¸€ã€OpenClawæ˜¯ä»€ä¹ˆï¼Ÿä¼ä¸šAIçš„ç‘å£«å†›åˆ€

### 1.1 ä»OpenAIåˆ°OpenClawï¼šè‡ªä¸»å¯æ§çš„AIä¹‹è·¯

è¿˜è®°å¾—2023å¹´å—ï¼Ÿé‚£æ—¶å€™ä¼ä¸šæƒ³è¦AIèƒ½åŠ›ï¼Œåªæœ‰ä¸€æ¡è·¯ï¼š**è°ƒç”¨OpenAI API**ã€‚

ä½†è¿™æ¡è·¯æœ‰ä¸‰å¤§ç—›ç‚¹ï¼š
- **æ•°æ®éšç§**ï¼šå…¬å¸æœºå¯†è¦ä¼ åˆ°å›½å¤–æœåŠ¡å™¨
- **æˆæœ¬ä¸å¯æ§**ï¼šTokenç”¨é‡åƒæµæ°´ï¼Œæœˆåº•è´¦å•å“ä¸€è·³
- **ç½‘ç»œä¾èµ–**ï¼šå†…ç½‘ç¯å¢ƒã€è·¨å›½å»¶è¿Ÿã€APIé™æµ

OpenClawçš„å‡ºç°ï¼Œå°±åƒç»™ä¼ä¸šå‘äº†ä¸€å°**"AIå‘ç”µæœº"**â€”â€”æŠŠå¤§æ¨¡å‹éƒ¨ç½²åœ¨è‡ªå·±æœåŠ¡å™¨ä¸Šï¼Œæ•°æ®ä¸å‡ºå†…ç½‘ï¼Œæˆæœ¬å¯æ§ï¼Œå“åº”é£å¿«ã€‚

### 1.2 OpenClaw vs Ollamaï¼šåŒå‰‘åˆç’§

å¾ˆå¤šäººé—®ï¼šæœ‰äº†Ollamaä¸ºä»€ä¹ˆè¿˜è¦OpenClawï¼Ÿ

| ç»´åº¦ | Ollama | OpenClaw |
|------|--------|----------|
| **å®šä½** | æœ¬åœ°æ¨¡å‹è¿è¡Œå·¥å…· | ä¼ä¸šçº§AIæœåŠ¡æ¡†æ¶ |
| **æ¨¡å‹æ”¯æŒ** | å¼€æºæ¨¡å‹ä¸ºä¸» | å›½äº§å•†ç”¨æ¨¡å‹ +
| **å¹¶å‘èƒ½åŠ›** | å•æœºå•ç”¨æˆ· | ä¼ä¸šçº§é«˜å¹¶å‘ |
| **ç®¡ç†åŠŸèƒ½** | åŸºç¡€CLI | å®Œæ•´ç®¡ç†åå° |
| **æ‰©å±•æ€§** | æ’ä»¶æœºåˆ¶ | ä¼ä¸šé›†æˆAPI |
| **é€‚ç”¨åœºæ™¯** | ä¸ªäºº/å°å›¢é˜Ÿ | ä¸­å¤§å‹ä¼ä¸š |

**æœ€ä½³å®è·µ**ï¼š
```
Ollamaè´Ÿè´£ï¼šæœ¬åœ°æ¨¡å‹è¿è¡Œã€å¿«é€ŸåŸå‹éªŒè¯
OpenClawè´Ÿè´£ï¼šä¼ä¸šçº§éƒ¨ç½²ã€å¤šæ¨¡å‹ç®¡ç†ã€ä¸šåŠ¡é›†æˆ
```

### 1.3 OpenClawçš„æ ¸å¿ƒæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OpenClaw æ¶æ„å›¾                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    API Gateway å±‚                        â”‚   â”‚
â”‚  â”‚  â€¢ RESTful API  â€¢ WebSocket  â€¢ è®¤è¯é‰´æƒ  â€¢ é™æµç†”æ–­      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Model Manager å±‚                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚
â”‚  â”‚  â”‚ é€šä¹‰åƒé—® â”‚ â”‚ æ–‡å¿ƒä¸€è¨€ â”‚ â”‚ DeepSeekâ”‚ â”‚  Llama  â”‚       â”‚   â”‚
â”‚  â”‚  â”‚  Qwen   â”‚ â”‚  ERNIE  â”‚ â”‚   V3    â”‚ â”‚   3.1   â”‚       â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚   â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚   â”‚
â”‚  â”‚                    ç»Ÿä¸€è°ƒåº¦æ¥å£                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                  Inference Engine å±‚                     â”‚   â”‚
â”‚  â”‚  â€¢ vLLM  â€¢ TensorRT-LLM  â€¢ llama.cpp  â€¢ è‡ªå®šä¹‰åç«¯      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    Storage å±‚                            â”‚   â”‚
â”‚  â”‚  â€¢ æ¨¡å‹ä»“åº“  â€¢ å¯¹è¯å†å²  â€¢ çŸ¥è¯†åº“  â€¢ é…ç½®ä¸­å¿ƒ            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## äºŒã€ç¯å¢ƒå‡†å¤‡ï¼šä»é›¶å¼€å§‹æ­å»º

### 2.1 ç¡¬ä»¶é…ç½®å»ºè®®

**å¼€å‘æµ‹è¯•ç¯å¢ƒ**ï¼š
```yaml
CPU: Intel i7-12700 / AMD Ryzen 7 5800X
å†…å­˜: 32GB DDR4
GPU: NVIDIA RTX 3090 (24GBæ˜¾å­˜)
å­˜å‚¨: 500GB NVMe SSD
ç½‘ç»œ: å†…ç½‘åƒå…†
```

**ç”Ÿäº§ç¯å¢ƒï¼ˆæ”¯æŒ50å¹¶å‘ï¼‰**ï¼š
```yaml
CPU: Intel Xeon Gold 6348 / AMD EPYC 7543
å†…å­˜: 128GB DDR4 ECC
GPU: 2x NVIDIA A100 40GB
å­˜å‚¨: 2TB NVMe SSD RAID1
ç½‘ç»œ: ä¸‡å…†å†…ç½‘ + è´Ÿè½½å‡è¡¡
```

### 2.2 è½¯ä»¶ç¯å¢ƒæ­å»º

**Step 1: å®‰è£…Dockerå’ŒDocker Compose**

```bash
# Ubuntu/Debian
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# å®‰è£…Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```

**Step 2: å®‰è£…NVIDIA Container Toolkit**

```bash
# æ·»åŠ NVIDIAä»“åº“
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# å®‰è£…
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

**Step 3: éªŒè¯GPUå¯ç”¨æ€§**

```bash
docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi
```

## ä¸‰ã€OpenClaw + Ollama è”åˆéƒ¨ç½²

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦è”åˆéƒ¨ç½²ï¼Ÿ

OpenClawä¸“æ³¨äº**ä¼ä¸šçº§ç®¡ç†å’Œè°ƒåº¦**ï¼ŒOllamaä¸“æ³¨äº**æœ¬åœ°æ¨¡å‹è¿è¡Œ**ã€‚ä¸¤è€…ç»“åˆï¼š

- OpenClawæä¾›ç»Ÿä¸€APIå’Œç®¡ç†ç•Œé¢
- Ollamaä½œä¸ºåç«¯æ¨ç†å¼•æ“ä¹‹ä¸€
- æ”¯æŒå¤šæ¨¡å‹çƒ­åˆ‡æ¢å’Œè´Ÿè½½å‡è¡¡

### 3.2 Docker Compose éƒ¨ç½²é…ç½®

åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  # Ollama æœåŠ¡
  ollama:
    image: ollama/ollama:latest
    container_name: openclaw-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_HOST=0.0.0.0
    networks:
      - openclaw-network

  # OpenClaw æ ¸å¿ƒæœåŠ¡
  openclaw:
    image: openclaw/openclaw:latest
    container_name: openclaw-core
    restart: unless-stopped
    ports:
      - "8080:8080"
      - "8081:8081"  # ç®¡ç†åå°
    volumes:
      - openclaw_data:/app/data
      - openclaw_models:/app/models
      - ./config:/app/config:ro
    environment:
      - OPENCLAW_MODE=production
      - OPENCLAW_DB_URL=postgresql://openclaw:password@postgres:5432/openclaw
      - OPENCLAW_REDIS_URL=redis://redis:6379/0
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - postgres
      - redis
      - ollama
    networks:
      - openclaw-network

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: openclaw-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: openclaw
      POSTGRES_PASSWORD: password
      POSTGRES_DB: openclaw
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - openclaw-network

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: openclaw-redis
    restart: unless-stopped
    volumes:
      - redis_data:/data
    networks:
      - openclaw-network

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: openclaw-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - openclaw
    networks:
      - openclaw-network

volumes:
  ollama_data:
  openclaw_data:
  openclaw_models:
  postgres_data:
  redis_data:

networks:
  openclaw-network:
    driver: bridge
```

### 3.3 å¯åŠ¨æœåŠ¡

```bash
# åˆ›å»ºé…ç½®ç›®å½•
mkdir -p config ssl

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# éªŒè¯æœåŠ¡çŠ¶æ€
docker-compose ps
```

### 3.4 é…ç½®å›½äº§æ¨¡å‹

åˆ›å»º `config/models.yml`ï¼š

```yaml
models:
  # é€šä¹‰åƒé—® 2.5
  qwen2.5:
    name: "é€šä¹‰åƒé—® 2.5"
    provider: ollama
    model_id: qwen2.5:72b
    max_tokens: 8192
    temperature: 0.7
    context_window: 32768
    capabilities:
      - chat
      - code
      - analysis
    priority: 1

  # DeepSeek V3
  deepseek-v3:
    name: "DeepSeek V3"
    provider: ollama
    model_id: deepseek-v3
    max_tokens: 8192
    temperature: 0.7
    context_window: 64000
    capabilities:
      - chat
      - code
      - reasoning
    priority: 2

  # æœ¬åœ°è½»é‡çº§æ¨¡å‹ï¼ˆå¤‡ç”¨ï¼‰
  qwen2.5-7b:
    name: "é€šä¹‰åƒé—® 2.5 (7Bè½»é‡ç‰ˆ)"
    provider: ollama
    model_id: qwen2.5:7b
    max_tokens: 4096
    temperature: 0.7
    context_window: 32768
    capabilities:
      - chat
      - quick_response
    priority: 3

# è·¯ç”±ç­–ç•¥
routing:
  default_model: qwen2.5
  fallback_enabled: true
  load_balance: round_robin
```

### 3.5 æ‹‰å–æ¨¡å‹

```bash
# è¿›å…¥Ollamaå®¹å™¨
docker exec -it openclaw-ollama bash

# æ‹‰å–é€šä¹‰åƒé—®
ollama pull qwen2.5:72b

# æ‹‰å–DeepSeek
ollama pull deepseek-v3

# æ‹‰å–è½»é‡ç‰ˆå¤‡ç”¨
ollama pull qwen2.5:7b

# æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹
ollama list
```

## å››ã€é£ä¹¦æœºå™¨äººé›†æˆå®æˆ˜

### 4.1 é£ä¹¦æœºå™¨äººåˆ›å»º

**Step 1: åˆ›å»ºä¼ä¸šè‡ªå»ºåº”ç”¨**

1. è¿›å…¥ [é£ä¹¦å¼€æ”¾å¹³å°](https://open.feishu.cn/)
2. ç‚¹å‡»"åˆ›å»ºä¼ä¸šè‡ªå»ºåº”ç”¨"
3. å¡«å†™åº”ç”¨åç§°ï¼š"OpenClaw AIåŠ©æ‰‹"
4. é€‰æ‹©åº”ç”¨ç±»å‹ï¼š"æœºå™¨äºº"

**Step 2: è·å–å‡­è¯**

åœ¨"å‡­è¯ä¸åŸºç¡€ä¿¡æ¯"é¡µé¢è·å–ï¼š
- `App ID` (app_id)
- `App Secret` (app_secret)
- `Verification Token` (verify_token)
- `Encrypt Key` (encrypt_key)

**Step 3: é…ç½®æƒé™**

åœ¨"æƒé™ç®¡ç†"ä¸­æ·»åŠ ä»¥ä¸‹æƒé™ï¼š
- `im:chat:readonly` - è¯»å–ç¾¤ç»„ä¿¡æ¯
- `im:message:send` - å‘é€æ¶ˆæ¯
- `im:message:receive` - æ¥æ”¶æ¶ˆæ¯
- `im:message.group_msg` - æ¥æ”¶ç¾¤æ¶ˆæ¯

**Step 4: é…ç½®äº‹ä»¶è®¢é˜…**

åœ¨"äº‹ä»¶è®¢é˜…"ä¸­è®¾ç½®ï¼š
- è¯·æ±‚åœ°å€ï¼š`https://your-domain.com/webhook/feishu`
- è®¢é˜…äº‹ä»¶ï¼š
  - `im.message.receive_v1` - æ¥æ”¶æ¶ˆæ¯
  - `im.chat.member.user.added_v1` - è¢«æ·»åŠ è¿›ç¾¤

### 4.2 å¼€å‘é£ä¹¦æœºå™¨äººæœåŠ¡

åˆ›å»º `feishu_bot.py`ï¼š

```python
#!/usr/bin/env python3
"""
OpenClaw é£ä¹¦æœºå™¨äººæœåŠ¡
å®ç°ä¸é£ä¹¦çš„æ¶ˆæ¯æ”¶å‘å’ŒOpenClawçš„é›†æˆ
"""

import asyncio
import json
import logging
import aiohttp
from typing import Optional, Dict, Any
from dataclasses import dataclass
from datetime import datetime
import hashlib
import hmac
import base64

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class FeishuConfig:
    """é£ä¹¦é…ç½®"""
    app_id: str
    app_secret: str
    verify_token: str
    encrypt_key: Optional[str] = None
    openclaw_base_url: str = "http://localhost:8080"
    default_model: str = "qwen2.5"


class OpenClawClient:
    """OpenClaw API å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def chat(
        self,
        message: str,
        model: str = "qwen2.5",
        conversation_id: Optional[str] = None,
        stream: bool = False
    ) -> Dict[str, Any]:
        """å‘é€èŠå¤©è¯·æ±‚åˆ°OpenClaw"""
        
        url = f"{self.base_url}/api/v1/chat"
        
        payload = {
            "model": model,
            "messages": [
                {"role": "user", "content": message}
            ],
            "stream": stream,
            "temperature": 0.7,
            "max_tokens": 2048
        }
        
        if conversation_id:
            payload["conversation_id"] = conversation_id
        
        try:
            async with self.session.post(url, json=payload) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    error_text = await response.text()
                    logger.error(f"OpenClaw APIé”™è¯¯: {response.status} - {error_text}")
                    return {
                        "error": f"APIé”™è¯¯: {response.status}",
                        "content": "æŠ±æ­‰ï¼ŒæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                    }
        except Exception as e:
            logger.error(f"è¯·æ±‚OpenClawå¤±è´¥: {e}")
            return {
                "error": str(e),
                "content": "æŠ±æ­‰ï¼Œè¿æ¥æœåŠ¡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚"
            }


class FeishuBot:
    """é£ä¹¦æœºå™¨äººæ ¸å¿ƒç±»"""
    
    def __init__(self, config: FeishuConfig):
        self.config = config
        self.access_token: Optional[str] = None
        self.token_expire_time: Optional[datetime] = None
        self.openclaw = OpenClawClient(config.openclaw_base_url)
        
        # ä¼šè¯ç®¡ç†
        self.conversations: Dict[str, str] = {}  # user_id -> conversation_id
    
    async def get_access_token(self) -> str:
        """è·å–é£ä¹¦è®¿é—®ä»¤ç‰Œ"""
        
        # æ£€æŸ¥ä»¤ç‰Œæ˜¯å¦æœ‰æ•ˆ
        if self.access_token and self.token_expire_time:
            if datetime.now() < self.token_expire_time:
                return self.access_token
        
        # è¯·æ±‚æ–°ä»¤ç‰Œ
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json={
                "app_id": self.config.app_id,
                "app_secret": self.config.app_secret
            }) as response:
                data = await response.json()
                
                if data.get("code") == 0:
                    self.access_token = data["tenant_access_token"]
                    # ä»¤ç‰Œæœ‰æ•ˆæœŸ2å°æ—¶ï¼Œæå‰5åˆ†é’Ÿåˆ·æ–°
                    self.token_expire_time = datetime.now().timestamp() + data["expire"] - 300
                    return self.access_token
                else:
                    raise Exception(f"è·å–è®¿é—®ä»¤ç‰Œå¤±è´¥: {data}")
    
    def verify_signature(self, timestamp: str, nonce: str, body: str, signature: str) -> bool:
        """éªŒè¯é£ä¹¦è¯·æ±‚ç­¾å"""
        
        # æ„é€ ç­¾åå­—ç¬¦ä¸²
        sign_str = f"{timestamp}\n{nonce}\n{body}\n"
        
        # è®¡ç®—ç­¾å
        computed = hmac.new(
            self.config.encrypt_key.encode(),
            sign_str.encode(),
            hashlib.sha256
        ).digest()
        computed_b64 = base64.b64encode(computed).decode()
        
        return computed_b64 == signature
    
    async def send_message(
        self,
        receive_id: str,
        content: str,
        msg_type: str = "text",
        receive_id_type: str = "open_id"
    ):
        """å‘é€æ¶ˆæ¯åˆ°é£ä¹¦"""
        
        token = await self.get_access_token()
        url = "https://open.feishu.cn/open-apis/im/v1/messages"
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        # æ„é€ æ¶ˆæ¯å†…å®¹
        if msg_type == "text":
            content_json = json.dumps({"text": content})
        elif msg_type == "markdown":
            content_json = json.dumps({"content": content})
        else:
            content_json = content
        
        params = {"receive_id_type": receive_id_type}
        payload = {
            "receive_id": receive_id,
            "msg_type": msg_type,
            "content": content_json
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                url,
                headers=headers,
                params=params,
                json=payload
            ) as response:
                data = await response.json()
                
                if data.get("code") != 0:
                    logger.error(f"å‘é€æ¶ˆæ¯å¤±è´¥: {data}")
                else:
                    logger.info(f"æ¶ˆæ¯å‘é€æˆåŠŸ: {receive_id}")
    
    async def handle_message(self, event: Dict[str, Any]):
        """å¤„ç†æ”¶åˆ°çš„æ¶ˆæ¯"""
        
        message = event.get("message", {})
        sender = event.get("sender", {})
        
        # è·å–å‘é€è€…ä¿¡æ¯
        sender_id = sender.get("sender_id", {}).get("open_id")
        sender_name = sender.get("sender_id", {}).get("name", "ç”¨æˆ·")
        
        # è·å–æ¶ˆæ¯å†…å®¹
        msg_type = message.get("message_type")
        content = json.loads(message.get("content", "{}"))
        
        # åªå¤„ç†æ–‡æœ¬æ¶ˆæ¯
        if msg_type != "text":
            await self.send_message(
                sender_id,
                "ç›®å‰æˆ‘åªæ”¯æŒæ–‡æœ¬æ¶ˆæ¯å“¦ï½",
                receive_id_type="open_id"
            )
            return
        
        user_message = content.get("text", "").strip()
        
        # å¿½ç•¥ç©ºæ¶ˆæ¯
        if not user_message:
            return
        
        logger.info(f"æ”¶åˆ°æ¶ˆæ¯ from {sender_name}: {user_message[:50]}...")
        
        # è·å–æˆ–åˆ›å»ºä¼šè¯ID
        conversation_id = self.conversations.get(sender_id)
        
        # æ˜¾ç¤º"æ­£åœ¨è¾“å…¥"
        await self.send_message(
            sender_id,
            "ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...",
            receive_id_type="open_id"
        )
        
        # è°ƒç”¨OpenClaw
        async with self.openclaw:
            response = await self.openclaw.chat(
                message=user_message,
                model=self.config.default_model,
                conversation_id=conversation_id
            )
        
        # ä¿å­˜ä¼šè¯ID
        if "conversation_id" in response:
            self.conversations[sender_id] = response["conversation_id"]
        
        # å‘é€å›å¤
        reply_content = response.get("content", "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é—®é¢˜ã€‚")
        
        # æ·»åŠ å¼•ç”¨æ ¼å¼
        formatted_reply = f"ğŸ’¬ **å›å¤**\n\n{reply_content}\n\n---\n*Powered by OpenClaw + {self.config.default_model}*"
        
        await self.send_message(
            sender_id,
            formatted_reply,
            msg_type="markdown",
            receive_id_type="open_id"
        )
    
    async def handle_event(self, event: Dict[str, Any]):
        """å¤„ç†é£ä¹¦äº‹ä»¶"""
        
        event_type = event.get("header", {}).get("event_type")
        
        if event_type == "im.message.receive_v1":
            await self.handle_message(event.get("event", {}))
        elif event_type == "im.chat.member.user.added_v1":
            # è¢«æ·»åŠ è¿›ç¾¤
            chat_id = event.get("event", {}).get("chat_id")
            await self.send_message(
                chat_id,
                "ğŸ‘‹ å¤§å®¶å¥½ï¼æˆ‘æ˜¯OpenClaw AIåŠ©æ‰‹ï¼Œ\n"
                "å¯ä»¥ç›´æ¥@æˆ‘æé—®ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨ï¼\n"
                "æ”¯æŒåŠŸèƒ½ï¼šé—®ç­”ã€ä»£ç ã€åˆ†æã€å†™ä½œ",
                receive_id_type="chat_id"
            )


# Flask WebhookæœåŠ¡
from flask import Flask, request, jsonify

app = Flask(__name__)

# åˆå§‹åŒ–æœºå™¨äºº
config = FeishuConfig(
    app_id="cli_xxxxxxxxxxxxxxxx",  # æ›¿æ¢ä¸ºä½ çš„App ID
    app_secret="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",  # æ›¿æ¢ä¸ºä½ çš„App Secret
    verify_token="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",  # æ›¿æ¢ä¸ºä½ çš„Verify Token
    encrypt_key="xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",  # æ›¿æ¢ä¸ºä½ çš„Encrypt Key
    openclaw_base_url="http://localhost:8080",
    default_model="qwen2.5"
)

bot = FeishuBot(config)


@app.route("/webhook/feishu", methods=["POST"])
def feishu_webhook():
    """é£ä¹¦Webhookå…¥å£"""
    
    data = request.get_json()
    
    # å¤„ç†URLéªŒè¯
    if data.get("type") == "url_verification":
        challenge = data.get("challenge")
        return jsonify({"challenge": challenge})
    
    # éªŒè¯ç­¾åï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®å¼€å¯ï¼‰
    # timestamp = request.headers.get("X-Lark-Request-Timestamp")
    # nonce = request.headers.get("X-Lark-Request-Nonce")
    # signature = request.headers.get("X-Lark-Signature")
    # body = request.get_data(as_text=True)
    # 
    # if not bot.verify_signature(timestamp, nonce, body, signature):
    #     return jsonify({"code": 403, "msg": "Invalid signature"}), 403
    
    # å¤„ç†äº‹ä»¶
    event = data.get("event")
    if event:
        asyncio.run(bot.handle_event(event))
    
    return jsonify({"code": 0, "msg": "success"})


@app.route("/health", methods=["GET"])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "service": "OpenClaw Feishu Bot",
        "timestamp": datetime.now().isoformat()
    })


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
```

### 4.3 éƒ¨ç½²æœºå™¨äººæœåŠ¡

åˆ›å»º `Dockerfile.bot`ï¼š

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç 
COPY feishu_bot.py .

# æš´éœ²ç«¯å£
EXPOSE 5000

# å¯åŠ¨æœåŠ¡
CMD ["python", "feishu_bot.py"]
```

åˆ›å»º `requirements.txt`ï¼š

```
flask==3.0.0
aiohttp==3.9.0
```

æ·»åŠ åˆ° `docker-compose.yml`ï¼š

```yaml
  feishu-bot:
    build:
      context: .
      dockerfile: Dockerfile.bot
    container_name: openclaw-feishu-bot
    restart: unless-stopped
    ports:
      - "5000:5000"
    environment:
      - FEISHU_APP_ID=cli_xxxxxxxxxxxxxxxx
      - FEISHU_APP_SECRET=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      - FEISHU_VERIFY_TOKEN=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      - FEISHU_ENCRYPT_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
      - OPENCLAW_BASE_URL=http://openclaw:8080
      - DEFAULT_MODEL=qwen2.5
    depends_on:
      - openclaw
    networks:
      - openclaw-network
```

### 4.4 é«˜çº§åŠŸèƒ½ï¼šçŸ¥è¯†åº“é›†æˆ

è®©æœºå™¨äººèƒ½å¤Ÿå›ç­”ä¼ä¸šå†…éƒ¨çŸ¥è¯†ï¼š

```python
class KnowledgeBase:
    """ä¼ä¸šçŸ¥è¯†åº“"""
    
    def __init__(self, openclaw_url: str):
        self.openclaw_url = openclaw_url
        self.documents = []
    
    async def add_document(self, title: str, content: str, metadata: Dict = None):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        
        url = f"{self.openclaw_url}/api/v1/knowledge/documents"
        
        payload = {
            "title": title,
            "content": content,
            "metadata": metadata or {}
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload) as response:
                return await response.json()
    
    async def query(self, question: str, top_k: int = 3) -> List[Dict]:
        """æ£€ç´¢ç›¸å…³çŸ¥è¯†"""
        
        url = f"{self.openclaw_url}/api/v1/knowledge/query"
        
        payload = {
            "query": question,
            "top_k": top_k
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(url, json=payload) as response:
                data = await response.json()
                return data.get("documents", [])
    
    async def chat_with_knowledge(
        self,
        message: str,
        model: str = "qwen2.5"
    ) -> str:
        """åŸºäºçŸ¥è¯†åº“å›ç­”"""
        
        # æ£€ç´¢ç›¸å…³çŸ¥è¯†
        relevant_docs = await self.query(message)
        
        # æ„å»ºå¢å¼ºæç¤º
        context = "\n\n".join([
            f"æ–‡æ¡£{i+1}: {doc['title']}\n{doc['content'][:500]}"
            for i, doc in enumerate(relevant_docs)
        ])
        
        enhanced_prompt = f"""åŸºäºä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ï¼š

{context}

ç”¨æˆ·é—®é¢˜ï¼š{message}

è¯·æ ¹æ®å‚è€ƒèµ„æ–™å›ç­”ï¼Œå¦‚æœèµ„æ–™ä¸è¶³ä»¥å›ç­”ï¼Œè¯·è¯´æ˜ã€‚"""
        
        # è°ƒç”¨æ¨¡å‹
        async with aiohttp.ClientSession() as session:
            url = f"{self.openclaw_url}/api/v1/chat"
            async with session.post(url, json={
                "model": model,
                "messages": [{"role": "user", "content": enhanced_prompt}]
            }) as response:
                data = await response.json()
                return data.get("content", "")


# åœ¨FeishuBotä¸­æ·»åŠ çŸ¥è¯†åº“æ”¯æŒ
class FeishuBotWithKB(FeishuBot):
    def __init__(self, config: FeishuConfig):
        super().__init__(config)
        self.kb = KnowledgeBase(config.openclaw_base_url)
    
    async def handle_message(self, event: Dict[str, Any]):
        """å¢å¼ºç‰ˆæ¶ˆæ¯å¤„ç†ï¼Œæ”¯æŒçŸ¥è¯†åº“"""
        
        message = event.get("message", {})
        sender = event.get("sender", {})
        sender_id = sender.get("sender_id", {}).get("open_id")
        
        content = json.loads(message.get("content", "{}"))
        user_message = content.get("text", "").strip()
        
        # æ£€æŸ¥æ˜¯å¦è§¦å‘çŸ¥è¯†åº“æ¨¡å¼
        if user_message.startswith("/kb "):
            # çŸ¥è¯†åº“æŸ¥è¯¢æ¨¡å¼
            query = user_message[4:]
            await self.send_message(sender_id, "ğŸ” æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“...")
            
            response = await self.kb.chat_with_knowledge(query)
            
            await self.send_message(
                sender_id,
                f"ğŸ“š **çŸ¥è¯†åº“å›ç­”**\n\n{response}",
                msg_type="markdown"
            )
        else:
            # æ™®é€šå¯¹è¯æ¨¡å¼
            await super().handle_message(event)
```

## äº”ã€ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

### 5.1 æ€§èƒ½ç›‘æ§

åˆ›å»ºç›‘æ§é…ç½® `prometheus.yml`ï¼š

```yaml
scrape_configs:
  - job_name: 'openclaw'
    static_configs:
      - targets: ['openclaw:8080']
  
  - job_name: 'ollama'
    static_configs:
      - targets: ['ollama:11434']
```

### 5.2 è´Ÿè½½å‡è¡¡é…ç½®

```nginx
# nginx.conf
upstream openclaw_backend {
    least_conn;
    server openclaw:8080 weight=5;
    server openclaw-backup:8080 backup;
}

server {
    listen 80;
    server_name ai.yourcompany.com;
    
    location / {
        proxy_pass http://openclaw_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        
        # WebSocketæ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

### 5.3 å¤‡ä»½ç­–ç•¥

```bash
#!/bin/bash
# backup.sh - æ¯æ—¥å¤‡ä»½è„šæœ¬

BACKUP_DIR="/backup/openclaw/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
docker exec openclaw-postgres pg_dump -U openclaw openclaw > $BACKUP_DIR/database.sql

# å¤‡ä»½é…ç½®
cp -r config $BACKUP_DIR/

# å¤‡ä»½æ¨¡å‹ï¼ˆå¯é€‰ï¼Œæ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼‰
# cp -r ollama_data $BACKUP_DIR/

# å‹ç¼©
 tar -czf $BACKUP_DIR.tar.gz $BACKUP_DIR
 rm -rf $BACKUP_DIR

# ä¿ç•™æœ€è¿‘7å¤©å¤‡ä»½
find /backup/openclaw -name "*.tar.gz" -mtime +7 -delete
```

## å…­ã€å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 6.1 æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜**ï¼šOllamaæ— æ³•åŠ è½½å¤§æ¨¡å‹ï¼Œæ˜¾å­˜ä¸è¶³

**è§£å†³**ï¼š
```bash
# ä½¿ç”¨é‡åŒ–ç‰ˆæœ¬
ollama pull qwen2.5:14b-q4_K_M

# æˆ–å¯ç”¨CPUæ¨ç†
OLLAMA_CPU_ONLY=1 ollama serve
```

### 6.2 é£ä¹¦æ¶ˆæ¯å»¶è¿Ÿ

**é—®é¢˜**ï¼šæ¶ˆæ¯å“åº”æ…¢ï¼Œç”¨æˆ·ä½“éªŒå·®

**è§£å†³**ï¼š
```python
# æ·»åŠ å¼‚æ­¥å¤„ç†å’Œæµå¼å“åº”
async def stream_response(self, message: str, sender_id: str):
    """æµå¼å“åº”ï¼Œæå‡ç”¨æˆ·ä½“éªŒ"""
    
    # å…ˆå‘é€"æ­£åœ¨è¾“å…¥"
    await self.send_message(sender_id, "ğŸ¤” æ€è€ƒä¸­...")
    
    # æµå¼è·å–å“åº”
    buffer = ""
    last_update = time.time()
    
    async for chunk in self.openclaw.stream_chat(message):
        buffer += chunk
        
        # æ¯2ç§’æ›´æ–°ä¸€æ¬¡æ¶ˆæ¯
        if time.time() - last_update > 2:
            await self.update_message(
                message_id,
                f"ğŸ’¬ å›å¤ä¸­...\n\n{buffer}..."
            )
            last_update = time.time()
    
    # å‘é€æœ€ç»ˆå›å¤
    await self.update_message(message_id, buffer)
```

### 6.3 é«˜å¹¶å‘å¤„ç†

**é—®é¢˜**ï¼šå¤šäººåŒæ—¶ä½¿ç”¨æ—¶å“åº”æ…¢

**è§£å†³**ï¼š
```yaml
# docker-compose.yml æ‰©å±•
services:
  openclaw:
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '4'
          memory: 16G
    
  ollama:
    deploy:
      replicas: 2
```

## ä¸ƒã€æ€»ç»“ï¼šä¼ä¸šAIçš„è‡ªä¸»å¯æ§ä¹‹è·¯

é€šè¿‡OpenClaw + Ollama + é£ä¹¦æœºå™¨äººçš„ç»„åˆï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

âœ… **æ•°æ®å®‰å…¨**ï¼šæ‰€æœ‰æ•°æ®ç•™åœ¨ä¼ä¸šå†…ç½‘  
âœ… **æˆæœ¬å¯æ§**ï¼šæ— éœ€æŒ‰Tokenä»˜è´¹ï¼Œä¸€æ¬¡æ€§æŠ•å…¥  
âœ… **å“åº”å¿«é€Ÿ**ï¼šå†…ç½‘å»¶è¿Ÿ<50ms  
âœ… **çµæ´»æ‰©å±•**ï¼šæ”¯æŒå¤šç§å›½äº§æ¨¡å‹å’Œä¸šåŠ¡é›†æˆ  
âœ… **ç”¨æˆ·ä½“éªŒ**ï¼šä¸é£ä¹¦æ— ç¼é›†æˆï¼Œé›¶å­¦ä¹ æˆæœ¬

è¿™ä¸ä»…æ˜¯æŠ€æœ¯çš„èƒœåˆ©ï¼Œæ›´æ˜¯**ä¼ä¸šAIè‡ªä¸»å¯æ§**çš„å®è·µã€‚

å½“å…¶ä»–å…¬å¸è¿˜åœ¨ä¸ºOpenAIçš„APIé™æµå‘æ„æ—¶ï¼Œä½ å·²ç»æ‹¥æœ‰äº†è‡ªå·±çš„AIåŸºç¡€è®¾æ–½ã€‚

å½“å…¶ä»–å…¬å¸æ‹…å¿ƒæ•°æ®æ³„éœ²æ—¶ï¼Œä½ çš„æ•°æ®å®‰å…¨åœ°è·‘åœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šã€‚

è¿™å°±æ˜¯OpenClaw + Ollamaå¸¦æ¥çš„**ä¼ä¸šçº§AIè‡ªç”±**ã€‚

---

**é¡¹ç›®åœ°å€**ï¼šhttps://github.com/openclaw/openclaw  
**æ–‡æ¡£ä¸­å¿ƒ**ï¼šhttps://docs.openclaw.io  
**ç¤¾åŒºè®ºå›**ï¼šhttps://forum.openclaw.io

**ç›¸å…³é˜…è¯»**ï¼š
- [Ollamaæ·±åº¦è§£æ](095-ollama-deep-dive.md)
- [AIå…¨é“¾è·¯çŸ¥è¯†å›¾è°±](098-ai-knowledge-map.md)
